{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "fetch_housing_data()\n",
    "housing = load_housing_data()\n",
    "housing.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocean_proximity\n",
       "<1H OCEAN     9136\n",
       "INLAND        6551\n",
       "ISLAND           5\n",
       "NEAR BAY      2290\n",
       "NEAR OCEAN    2658\n",
       "Name: housing_median_age, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.groupby(['ocean_proximity']).housing_median_age.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             False\n",
       "latitude              False\n",
       "housing_median_age    False\n",
       "total_rooms           False\n",
       "total_bedrooms         True\n",
       "population            False\n",
       "households            False\n",
       "median_income         False\n",
       "median_house_value    False\n",
       "ocean_proximity       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.shape   # 207 missin values in CA housing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummies['total_bedrooms'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummies.columns\n",
    "\n",
    "#fill Na with 0\n",
    "#X = data.iloc[:, [0,3,4,7,13]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=data_dummies[['longitude', 'latitude', 'housing_median_age', 'total_rooms','total_bedrooms', 'population',\n",
    "               'households', 'median_income','ocean_proximity_INLAND','ocean_proximity_ISLAND', 'ocean_proximity_NEAR BAY']]\n",
    "y=data_dummies['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2754: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude                   False\n",
       "latitude                    False\n",
       "housing_median_age          False\n",
       "total_rooms                 False\n",
       "total_bedrooms              False\n",
       "population                  False\n",
       "households                  False\n",
       "median_income               False\n",
       "ocean_proximity_INLAND      False\n",
       "ocean_proximity_ISLAND      False\n",
       "ocean_proximity_NEAR BAY    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,random_state=42)\n",
    "##feature scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sc_y = StandardScaler()\n",
    "# y_train = sc_y.fit_transform(y_train)\n",
    "# y_test=sc_y.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##i  want to run a model with linear regression and see the error terms\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn import  linear_model\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# # Create linear regression object\n",
    "# regressor = linear_model.LinearRegression()\n",
    "\n",
    "# # Train the model using the training sets\n",
    "# regressor.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions using the testing set\n",
    "# y_pred = regressor.predict(X_test)\n",
    "\n",
    "# # The coefficients\n",
    "# print('Coefficients: \\n', regressor.coef_)\n",
    "# # The mean squared error\n",
    "# print(\"Mean squared error: %.2f\"\n",
    "#       % mean_squared_error(y_test, y_pred))\n",
    "# # Explained variance score: 1 is perfect prediction\n",
    "# print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "# regressor.score(X_train,y_train)  ##  0.64665298256379455   quite bad under fitting\n",
    "# regressor.score(X_test,y_test)  ##  0.63226680319605766\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.ensemble import AdaBoostRegressor\n",
    "# from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "\n",
    "# tree = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "# linear_reg = LinearRegression().fit(X_train, y_train)\n",
    "# tree.score(X_train, y_train)\n",
    "# tree.fit(X_train, (y_train))\n",
    "# scores = cross_val_score(tree, X_train,np.log(y_train))\n",
    "# scores.mean()\n",
    "# print(tree.score(X_train,np.log(y_train)))\n",
    "# print(\"Test set R^2 Decision tree: {:.2f}\".format(tree.score(X_test, y_test)))\n",
    "# #Addaboost\n",
    "# #addaboost to Decision tree\n",
    "\n",
    "# clfboost = AdaBoostRegressor(DecisionTreeRegressor(max_depth=2),n_estimators=100, learning_rate=1)\n",
    "# clfboost.fit(X_train, y_train)\n",
    "# print(\"Training set score boost: {:.2f}\".format(clfboost.score(X_train, y_train)))\n",
    "# print(\"Training set score  boost: {:.2f}\".format(clfboost.score(X_test, y_test)))\n",
    "# boost_pred=clfboost.predict(X_test)\n",
    "\n",
    "# linear_reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# print(\"lr.coef_: {}\".format(linear_reg.coef_))\n",
    "# print(\"lr.intercept_: {}\".format(linear_reg.intercept_))\n",
    "# print(\"Training set score LR: {:.2f}\".format(linear_reg.score(X_train, y_train)))\n",
    "# print(\"Test set score  LR : {:.2f}\".format(linear_reg.score(X_test, y_test)))\n",
    "\n",
    "# print(\"Training set score  R^2 DT: {:.2f}\".format(tree.score(X_train, y_train)))\n",
    "# print(\"Test set score DT R^2 : {:.2f}\".format(tree.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# #forest = RandomForestRegressor(n_estimators=99, random_state=42, n_jobs=-1)\n",
    "# #forest.fit(X_train, np.log(y_train))\n",
    "# #y_pred=forest.predict(X_test)\n",
    "# #print(forest.feature_importances_)\n",
    "# #forest.score(X_train,np.log(y_train))#  0.97366914519019843\n",
    "# #forest.score(X_test,np.log(y_test))#0.83300797423108563\n",
    "\n",
    "\n",
    "# #gridsearch to find bets parameters and Cross validation to get the best score for generalization \n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "# X_trainval, X_test, y_trainval,y_test=train_test_split(X, y, test_size=0.35,random_state=42)\n",
    "# X_train, X_valid, y_train,y_valid=train_test_split(X_trainval, y_trainval, test_size=0.35,random_state=42)\n",
    "\n",
    "# print(\"size of training set:{}   size of validation set:{}   size of test set:\" \"{}\\n\".format(X_train.shape[0], X_valid.shape[0],X_test.shape[0]))\n",
    "\n",
    "# param_grid = { \n",
    "#     'n_estimators': [200, 700],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2']\n",
    "# }\n",
    "# clf = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "# clf.fit(X_train, y_train)\n",
    "# score=clf.score(X_valid, y_valid)\n",
    "\n",
    "# print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score0.8151808095797171\n",
      "train score 0.9746225642470652\n",
      "0.813221160328\n",
      "0.0193482285282\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000042475D5E40, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000042475D5E40, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 18, 33, 0, 368961, tzinfo=datetime.timezone.utc), 'msg_id': 'B9662B9CE7114E958E092BA55C3A1C07', 'msg_type': 'execute_request', 'session': '24FBFF33AA504F27AAB6CB8BD2260264', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'B9662B9CE7114E958E092BA55C3A1C07', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'24FBFF33AA504F27AAB6CB8BD2260264']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 18, 33, 0, 368961, tzinfo=datetime.timezone.utc), 'msg_id': 'B9662B9CE7114E958E092BA55C3A1C07', 'msg_type': 'execute_request', 'session': '24FBFF33AA504F27AAB6CB8BD2260264', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'B9662B9CE7114E958E092BA55C3A1C07', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'24FBFF33AA504F27AAB6CB8BD2260264'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 18, 33, 0, 368961, tzinfo=datetime.timezone.utc), 'msg_id': 'B9662B9CE7114E958E092BA55C3A1C07', 'msg_type': 'execute_request', 'session': '24FBFF33AA504F27AAB6CB8BD2260264', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'B9662B9CE7114E958E092BA55C3A1C07', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-17-7fdf28e0486d>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 424e4e1ba8, execution..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000000424A031A50, file \"<ipython-input-17-7fdf28e0486d>\", line 15>\n        result = <ExecutionResult object at 424e4e1ba8, execution..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000000424A031A50, file \"<ipython-input-17-7fdf28e0486d>\", line 15>, result=<ExecutionResult object at 424e4e1ba8, execution..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000000424A031A50, file \"<ipython-input-17-7fdf28e0486d>\", line 15>\n        self.user_global_ns = {'DOWNLOAD_ROOT': 'https://raw.githubusercontent.com/ageron/handson-ml/master/', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'HOUSING_PATH': r'datasets\\housing', 'HOUSING_URL': 'https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.tgz', 'In': ['', 'import os\\nimport tarfile\\nfrom six.moves import u...ta()\\nhousing = load_housing_data()\\nhousing.head()', \"housing.isnull().any(axis=0)\\n#create dummies for...core {}'.format(gridsearch.score(X_test,y_test)))\", \"housing.isnull().any(axis=0)\\n#create dummies for...core {}'.format(gridsearch.score(X_test,y_test)))\", \"housing.groupby(['ocean_proximity']).housing_median_age.count()\", 'housing.isnull().any(axis=0)', \"X=data_dummies[['longitude', 'latitude', 'housin..._NEAR BAY']]\\ny=data_dummies['median_house_value']\", 'X.fillna(0, inplace=True)', 'X.isnull().any(axis=0)', 'from sklearn.cross_validation import train_test_..._test_split(X, y, test_size=0.30,random_state=42)', '##feature scaling \\nfrom sklearn.preprocessing im...form(y_train)\\n# y_test=sc_y.fit_transform(y_test)', \"#X_train, X_test, y_train, y_test = train_test_s...core {}'.format(gridsearch.score(X_test,y_test)))\", \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\", \"print('best accuracy with random forest gridsear...t gridsearch {}'.format(gridsearch.best_params_))\", '\\n# sc_y = StandardScaler()\\n# y_train = sc_y.fit_...form(y_train)\\n# y_test=sc_y.fit_transform(y_test)', \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\", \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\", \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\"], 'Out': {1:    longitude  latitude  housing_median_age  tota...     3.8462            342200.0        NEAR BAY  , 4: ocean_proximity\n<1H OCEAN     9136\nINLAND       ...AN    2658\nName: housing_median_age, dtype: int64, 5: longitude             False\nlatitude            ...    False\nocean_proximity       False\ndtype: bool, 8: longitude                   False\nlatitude      ...lse\nocean_proximity_NEAR BAY    False\ndtype: bool}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'X':        longitude  latitude  housing_median_age  ...                   0  \n\n[20640 rows x 11 columns], 'X_test': array([[ 0.28664112,  0.19166399, -0.28346293, .... -0.68486433,\n        -0.01664126, -0.35549129]]), ...}\n        self.user_ns = {'DOWNLOAD_ROOT': 'https://raw.githubusercontent.com/ageron/handson-ml/master/', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'HOUSING_PATH': r'datasets\\housing', 'HOUSING_URL': 'https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.tgz', 'In': ['', 'import os\\nimport tarfile\\nfrom six.moves import u...ta()\\nhousing = load_housing_data()\\nhousing.head()', \"housing.isnull().any(axis=0)\\n#create dummies for...core {}'.format(gridsearch.score(X_test,y_test)))\", \"housing.isnull().any(axis=0)\\n#create dummies for...core {}'.format(gridsearch.score(X_test,y_test)))\", \"housing.groupby(['ocean_proximity']).housing_median_age.count()\", 'housing.isnull().any(axis=0)', \"X=data_dummies[['longitude', 'latitude', 'housin..._NEAR BAY']]\\ny=data_dummies['median_house_value']\", 'X.fillna(0, inplace=True)', 'X.isnull().any(axis=0)', 'from sklearn.cross_validation import train_test_..._test_split(X, y, test_size=0.30,random_state=42)', '##feature scaling \\nfrom sklearn.preprocessing im...form(y_train)\\n# y_test=sc_y.fit_transform(y_test)', \"#X_train, X_test, y_train, y_test = train_test_s...core {}'.format(gridsearch.score(X_test,y_test)))\", \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\", \"print('best accuracy with random forest gridsear...t gridsearch {}'.format(gridsearch.best_params_))\", '\\n# sc_y = StandardScaler()\\n# y_train = sc_y.fit_...form(y_train)\\n# y_test=sc_y.fit_transform(y_test)', \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\", \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\", \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\"], 'Out': {1:    longitude  latitude  housing_median_age  tota...     3.8462            342200.0        NEAR BAY  , 4: ocean_proximity\n<1H OCEAN     9136\nINLAND       ...AN    2658\nName: housing_median_age, dtype: int64, 5: longitude             False\nlatitude            ...    False\nocean_proximity       False\ndtype: bool, 8: longitude                   False\nlatitude      ...lse\nocean_proximity_NEAR BAY    False\ndtype: bool}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'X':        longitude  latitude  housing_median_age  ...                   0  \n\n[20640 rows x 11 columns], 'X_test': array([[ 0.28664112,  0.19166399, -0.28346293, .... -0.68486433,\n        -0.01664126, -0.35549129]]), ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Atena\\<ipython-input-17-7fdf28e0486d> in <module>()\n     10 print(accuracies.std())\n     11 #grid search\n     12 from sklearn.grid_search import GridSearchCV\n     13 parameters=[{'n_estimators':[90 ,100,120,180], 'max_depth':[1,2,3] , 'max_fearures':['auto','sqrt','log2']}]\n     14 gridsearch = GridSearchCV(estimator=forest   ,param_grid=parameters, cv=10, n_jobs=-1)\n---> 15 gridsearch=gridsearch.fit(X_train, y_train)\n     16 best_accuracy_forest=gridsearch.best_score_\n     17 best_parameter_forest=gridsearch.best_params_\n     18 print( 'grid search score {}'.format(gridsearch.score(X_test,y_test)))\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=10, error_score='raise',\n       ...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[ 0.78093406, -0.80568191,  0.50935748, .... -0.68486433,\n        -0.01664126,  2.81300847]]), y=7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64)\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X = array([[ 0.78093406, -0.80568191,  0.50935748, .... -0.68486433,\n        -0.01664126,  2.81300847]])\n        y = 7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64\n        self.param_grid = [{'max_depth': [1, 2, 3], 'max_fearures': ['auto', 'sqrt', 'log2'], 'n_estimators': [90, 100, 120, 180]}]\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=10, error_score='raise',\n       ...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[ 0.78093406, -0.80568191,  0.50935748, .... -0.68486433,\n        -0.01664126,  2.81300847]]), y=7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Apr 12 14:35:20 2018\nPID: 11148                Python 3.6.3: C:\\Users\\Atena\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), memmap([[ 0.78093406, -0.80568191,  0.50935748, ...-0.68486433,\n         -0.01664126,  2.81300847]]), 7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, <function _passthrough_scorer>, array([ 1445,  1446,  1447, ..., 14445, 14446, 14447]), array([   0,    1,    2, ..., 1442, 1443, 1444]), 0, {'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), memmap([[ 0.78093406, -0.80568191,  0.50935748, ...-0.68486433,\n         -0.01664126,  2.81300847]]), 7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, <function _passthrough_scorer>, array([ 1445,  1446,  1447, ..., 14445, 14446, 14447]), array([   0,    1,    2, ..., 1442, 1443, 1444]), 0, {'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), X=memmap([[ 0.78093406, -0.80568191,  0.50935748, ...-0.68486433,\n         -0.01664126,  2.81300847]]), y=7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, scorer=<function _passthrough_scorer>, train=array([ 1445,  1446,  1447, ..., 14445, 14446, 14447]), test=array([   0,    1,    2, ..., 1442, 1443, 1444]), verbose=0, parameters={'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1659     fit_params = fit_params if fit_params is not None else {}\n   1660     fit_params = dict([(k, _index_param_value(X, v, train))\n   1661                       for k, v in fit_params.items()])\n   1662 \n   1663     if parameters is not None:\n-> 1664         estimator.set_params(**parameters)\n        estimator.set_params = <bound method BaseEstimator.set_params of Random... random_state=None, verbose=0, warm_start=False)>\n        parameters = {'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}\n   1665 \n   1666     start_time = time.time()\n   1667 \n   1668     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), **params={'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'max_fearures'\n        self = RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter max_fearures for estimator RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=1,\n           max_features='auto', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n           oob_score=False, random_state=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\", line 1664, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 274, in set_params\n    (key, self))\nValueError: Invalid parameter max_fearures for estimator RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=1,\n           max_features='auto', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n           oob_score=False, random_state=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Atena\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Apr 12 14:35:20 2018\nPID: 11148                Python 3.6.3: C:\\Users\\Atena\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), memmap([[ 0.78093406, -0.80568191,  0.50935748, ...-0.68486433,\n         -0.01664126,  2.81300847]]), 7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, <function _passthrough_scorer>, array([ 1445,  1446,  1447, ..., 14445, 14446, 14447]), array([   0,    1,    2, ..., 1442, 1443, 1444]), 0, {'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), memmap([[ 0.78093406, -0.80568191,  0.50935748, ...-0.68486433,\n         -0.01664126,  2.81300847]]), 7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, <function _passthrough_scorer>, array([ 1445,  1446,  1447, ..., 14445, 14446, 14447]), array([   0,    1,    2, ..., 1442, 1443, 1444]), 0, {'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), X=memmap([[ 0.78093406, -0.80568191,  0.50935748, ...-0.68486433,\n         -0.01664126,  2.81300847]]), y=7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, scorer=<function _passthrough_scorer>, train=array([ 1445,  1446,  1447, ..., 14445, 14446, 14447]), test=array([   0,    1,    2, ..., 1442, 1443, 1444]), verbose=0, parameters={'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1659     fit_params = fit_params if fit_params is not None else {}\n   1660     fit_params = dict([(k, _index_param_value(X, v, train))\n   1661                       for k, v in fit_params.items()])\n   1662 \n   1663     if parameters is not None:\n-> 1664         estimator.set_params(**parameters)\n        estimator.set_params = <bound method BaseEstimator.set_params of Random... random_state=None, verbose=0, warm_start=False)>\n        parameters = {'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}\n   1665 \n   1666     start_time = time.time()\n   1667 \n   1668     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), **params={'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'max_fearures'\n        self = RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter max_fearures for estimator RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=1,\n           max_features='auto', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n           oob_score=False, random_state=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Apr 12 14:35:20 2018\nPID: 11148                Python 3.6.3: C:\\Users\\Atena\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), memmap([[ 0.78093406, -0.80568191,  0.50935748, ...-0.68486433,\n         -0.01664126,  2.81300847]]), 7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, <function _passthrough_scorer>, array([ 1445,  1446,  1447, ..., 14445, 14446, 14447]), array([   0,    1,    2, ..., 1442, 1443, 1444]), 0, {'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), memmap([[ 0.78093406, -0.80568191,  0.50935748, ...-0.68486433,\n         -0.01664126,  2.81300847]]), 7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, <function _passthrough_scorer>, array([ 1445,  1446,  1447, ..., 14445, 14446, 14447]), array([   0,    1,    2, ..., 1442, 1443, 1444]), 0, {'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), X=memmap([[ 0.78093406, -0.80568191,  0.50935748, ...-0.68486433,\n         -0.01664126,  2.81300847]]), y=7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, scorer=<function _passthrough_scorer>, train=array([ 1445,  1446,  1447, ..., 14445, 14446, 14447]), test=array([   0,    1,    2, ..., 1442, 1443, 1444]), verbose=0, parameters={'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1659     fit_params = fit_params if fit_params is not None else {}\n   1660     fit_params = dict([(k, _index_param_value(X, v, train))\n   1661                       for k, v in fit_params.items()])\n   1662 \n   1663     if parameters is not None:\n-> 1664         estimator.set_params(**parameters)\n        estimator.set_params = <bound method BaseEstimator.set_params of Random... random_state=None, verbose=0, warm_start=False)>\n        parameters = {'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}\n   1665 \n   1666     start_time = time.time()\n   1667 \n   1668     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), **params={'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'max_fearures'\n        self = RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter max_fearures for estimator RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=1,\n           max_features='auto', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n           oob_score=False, random_state=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-7fdf28e0486d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m90\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'max_fearures'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sqrt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'log2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mgridsearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforest\u001b[0m   \u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mgridsearch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgridsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mbest_accuracy_forest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgridsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mbest_parameter_forest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgridsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \"\"\"\n\u001b[1;32m--> 838\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 574\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m                 for train, test in cv)\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000042475D5E40, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000042475D5E40, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 18, 33, 0, 368961, tzinfo=datetime.timezone.utc), 'msg_id': 'B9662B9CE7114E958E092BA55C3A1C07', 'msg_type': 'execute_request', 'session': '24FBFF33AA504F27AAB6CB8BD2260264', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'B9662B9CE7114E958E092BA55C3A1C07', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'24FBFF33AA504F27AAB6CB8BD2260264']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 18, 33, 0, 368961, tzinfo=datetime.timezone.utc), 'msg_id': 'B9662B9CE7114E958E092BA55C3A1C07', 'msg_type': 'execute_request', 'session': '24FBFF33AA504F27AAB6CB8BD2260264', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'B9662B9CE7114E958E092BA55C3A1C07', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'24FBFF33AA504F27AAB6CB8BD2260264'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 18, 33, 0, 368961, tzinfo=datetime.timezone.utc), 'msg_id': 'B9662B9CE7114E958E092BA55C3A1C07', 'msg_type': 'execute_request', 'session': '24FBFF33AA504F27AAB6CB8BD2260264', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'B9662B9CE7114E958E092BA55C3A1C07', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"from sklearn.ensemble import RandomForestRegress...ore {}'.format(gridsearch.score(X_test,y_test)))\\n\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-17-7fdf28e0486d>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 424e4e1ba8, execution..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000000424A031A50, file \"<ipython-input-17-7fdf28e0486d>\", line 15>\n        result = <ExecutionResult object at 424e4e1ba8, execution..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000000424A031A50, file \"<ipython-input-17-7fdf28e0486d>\", line 15>, result=<ExecutionResult object at 424e4e1ba8, execution..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000000424A031A50, file \"<ipython-input-17-7fdf28e0486d>\", line 15>\n        self.user_global_ns = {'DOWNLOAD_ROOT': 'https://raw.githubusercontent.com/ageron/handson-ml/master/', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'HOUSING_PATH': r'datasets\\housing', 'HOUSING_URL': 'https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.tgz', 'In': ['', 'import os\\nimport tarfile\\nfrom six.moves import u...ta()\\nhousing = load_housing_data()\\nhousing.head()', \"housing.isnull().any(axis=0)\\n#create dummies for...core {}'.format(gridsearch.score(X_test,y_test)))\", \"housing.isnull().any(axis=0)\\n#create dummies for...core {}'.format(gridsearch.score(X_test,y_test)))\", \"housing.groupby(['ocean_proximity']).housing_median_age.count()\", 'housing.isnull().any(axis=0)', \"X=data_dummies[['longitude', 'latitude', 'housin..._NEAR BAY']]\\ny=data_dummies['median_house_value']\", 'X.fillna(0, inplace=True)', 'X.isnull().any(axis=0)', 'from sklearn.cross_validation import train_test_..._test_split(X, y, test_size=0.30,random_state=42)', '##feature scaling \\nfrom sklearn.preprocessing im...form(y_train)\\n# y_test=sc_y.fit_transform(y_test)', \"#X_train, X_test, y_train, y_test = train_test_s...core {}'.format(gridsearch.score(X_test,y_test)))\", \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\", \"print('best accuracy with random forest gridsear...t gridsearch {}'.format(gridsearch.best_params_))\", '\\n# sc_y = StandardScaler()\\n# y_train = sc_y.fit_...form(y_train)\\n# y_test=sc_y.fit_transform(y_test)', \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\", \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\", \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\"], 'Out': {1:    longitude  latitude  housing_median_age  tota...     3.8462            342200.0        NEAR BAY  , 4: ocean_proximity\n<1H OCEAN     9136\nINLAND       ...AN    2658\nName: housing_median_age, dtype: int64, 5: longitude             False\nlatitude            ...    False\nocean_proximity       False\ndtype: bool, 8: longitude                   False\nlatitude      ...lse\nocean_proximity_NEAR BAY    False\ndtype: bool}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'X':        longitude  latitude  housing_median_age  ...                   0  \n\n[20640 rows x 11 columns], 'X_test': array([[ 0.28664112,  0.19166399, -0.28346293, .... -0.68486433,\n        -0.01664126, -0.35549129]]), ...}\n        self.user_ns = {'DOWNLOAD_ROOT': 'https://raw.githubusercontent.com/ageron/handson-ml/master/', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'HOUSING_PATH': r'datasets\\housing', 'HOUSING_URL': 'https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.tgz', 'In': ['', 'import os\\nimport tarfile\\nfrom six.moves import u...ta()\\nhousing = load_housing_data()\\nhousing.head()', \"housing.isnull().any(axis=0)\\n#create dummies for...core {}'.format(gridsearch.score(X_test,y_test)))\", \"housing.isnull().any(axis=0)\\n#create dummies for...core {}'.format(gridsearch.score(X_test,y_test)))\", \"housing.groupby(['ocean_proximity']).housing_median_age.count()\", 'housing.isnull().any(axis=0)', \"X=data_dummies[['longitude', 'latitude', 'housin..._NEAR BAY']]\\ny=data_dummies['median_house_value']\", 'X.fillna(0, inplace=True)', 'X.isnull().any(axis=0)', 'from sklearn.cross_validation import train_test_..._test_split(X, y, test_size=0.30,random_state=42)', '##feature scaling \\nfrom sklearn.preprocessing im...form(y_train)\\n# y_test=sc_y.fit_transform(y_test)', \"#X_train, X_test, y_train, y_test = train_test_s...core {}'.format(gridsearch.score(X_test,y_test)))\", \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\", \"print('best accuracy with random forest gridsear...t gridsearch {}'.format(gridsearch.best_params_))\", '\\n# sc_y = StandardScaler()\\n# y_train = sc_y.fit_...form(y_train)\\n# y_test=sc_y.fit_transform(y_test)', \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\", \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\", \"from sklearn.ensemble import RandomForestRegress...core {}'.format(gridsearch.score(X_test,y_test)))\"], 'Out': {1:    longitude  latitude  housing_median_age  tota...     3.8462            342200.0        NEAR BAY  , 4: ocean_proximity\n<1H OCEAN     9136\nINLAND       ...AN    2658\nName: housing_median_age, dtype: int64, 5: longitude             False\nlatitude            ...    False\nocean_proximity       False\ndtype: bool, 8: longitude                   False\nlatitude      ...lse\nocean_proximity_NEAR BAY    False\ndtype: bool}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'X':        longitude  latitude  housing_median_age  ...                   0  \n\n[20640 rows x 11 columns], 'X_test': array([[ 0.28664112,  0.19166399, -0.28346293, .... -0.68486433,\n        -0.01664126, -0.35549129]]), ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Atena\\<ipython-input-17-7fdf28e0486d> in <module>()\n     10 print(accuracies.std())\n     11 #grid search\n     12 from sklearn.grid_search import GridSearchCV\n     13 parameters=[{'n_estimators':[90 ,100,120,180], 'max_depth':[1,2,3] , 'max_fearures':['auto','sqrt','log2']}]\n     14 gridsearch = GridSearchCV(estimator=forest   ,param_grid=parameters, cv=10, n_jobs=-1)\n---> 15 gridsearch=gridsearch.fit(X_train, y_train)\n     16 best_accuracy_forest=gridsearch.best_score_\n     17 best_parameter_forest=gridsearch.best_params_\n     18 print( 'grid search score {}'.format(gridsearch.score(X_test,y_test)))\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=10, error_score='raise',\n       ...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[ 0.78093406, -0.80568191,  0.50935748, .... -0.68486433,\n        -0.01664126,  2.81300847]]), y=7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64)\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X = array([[ 0.78093406, -0.80568191,  0.50935748, .... -0.68486433,\n        -0.01664126,  2.81300847]])\n        y = 7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64\n        self.param_grid = [{'max_depth': [1, 2, 3], 'max_fearures': ['auto', 'sqrt', 'log2'], 'n_estimators': [90, 100, 120, 180]}]\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=10, error_score='raise',\n       ...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[ 0.78093406, -0.80568191,  0.50935748, .... -0.68486433,\n        -0.01664126,  2.81300847]]), y=7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Apr 12 14:35:20 2018\nPID: 11148                Python 3.6.3: C:\\Users\\Atena\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), memmap([[ 0.78093406, -0.80568191,  0.50935748, ...-0.68486433,\n         -0.01664126,  2.81300847]]), 7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, <function _passthrough_scorer>, array([ 1445,  1446,  1447, ..., 14445, 14446, 14447]), array([   0,    1,    2, ..., 1442, 1443, 1444]), 0, {'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), memmap([[ 0.78093406, -0.80568191,  0.50935748, ...-0.68486433,\n         -0.01664126,  2.81300847]]), 7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, <function _passthrough_scorer>, array([ 1445,  1446,  1447, ..., 14445, 14446, 14447]), array([   0,    1,    2, ..., 1442, 1443, 1444]), 0, {'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), X=memmap([[ 0.78093406, -0.80568191,  0.50935748, ...-0.68486433,\n         -0.01664126,  2.81300847]]), y=7061     193800.0\n14689    169700.0\n17323    259...median_house_value, Length: 14448, dtype: float64, scorer=<function _passthrough_scorer>, train=array([ 1445,  1446,  1447, ..., 14445, 14446, 14447]), test=array([   0,    1,    2, ..., 1442, 1443, 1444]), verbose=0, parameters={'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1659     fit_params = fit_params if fit_params is not None else {}\n   1660     fit_params = dict([(k, _index_param_value(X, v, train))\n   1661                       for k, v in fit_params.items()])\n   1662 \n   1663     if parameters is not None:\n-> 1664         estimator.set_params(**parameters)\n        estimator.set_params = <bound method BaseEstimator.set_params of Random... random_state=None, verbose=0, warm_start=False)>\n        parameters = {'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90}\n   1665 \n   1666     start_time = time.time()\n   1667 \n   1668     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Atena\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False), **params={'max_depth': 1, 'max_fearures': 'auto', 'n_estimators': 90})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'max_fearures'\n        self = RandomForestRegressor(bootstrap=True, criterion=..., random_state=None, verbose=0, warm_start=False)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter max_fearures for estimator RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=1,\n           max_features='auto', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n           oob_score=False, random_state=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest = RandomForestRegressor(n_estimators=100, n_jobs=-1 )\n",
    "forest.fit(X_train, y_train)\n",
    "print('test score{}'.format(forest.score(X_test,y_test)))\n",
    "print('train score {}'.format(forest.score(X_train,y_train)))\n",
    "#kfold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies=cross_val_score(estimator=forest, X=X_train, y=y_train, cv=10)\n",
    "print(accuracies.mean())\n",
    "print(accuracies.std())\n",
    "#grid search\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "parameters=[{'n_estimators':[90 ,100,120,180], 'max_depth':[1,2,3] , 'max_fearures':['auto','sqrt','log2']}]\n",
    "gridsearch = GridSearchCV(estimator=forest   ,param_grid=parameters, cv=10, n_jobs=-1)\n",
    "gridsearch=gridsearch.fit(X_train, y_train)\n",
    "best_accuracy_forest=gridsearch.best_score_\n",
    "best_parameter_forest=gridsearch.best_params_\n",
    "print( 'grid search score {}'.format(gridsearch.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy with random forest gridsearch 0.5836825664193885\n",
      "best parameter with random forest gridsearch {'max_depth': 3, 'n_estimators': 120}\n"
     ]
    }
   ],
   "source": [
    "print('best accuracy with random forest gridsearch {}'.format(gridsearch.best_score_))\n",
    "print('best parameter with random forest gridsearch {}'.format(gridsearch.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_accuracy_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_parameter_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gridsearch.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=42)\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# # instantiate the model and set the number of neighbors to consider to 3:\n",
    "# regressorKNN = KNeighborsRegressor()\n",
    "# # fit the model using the training data and training targets:\n",
    "# regressorKNN.fit(X_train, y_train)\n",
    "# regressorKNN.score(X_test,y_test)#0.14842171151589068\n",
    "# regressorKNN.score(X_train,y_train)  ##0.60138713702971902\n",
    "\n",
    "\n",
    "# #print(\"Test set predictions:\\n{}\".format(regressorKNN.predict(X_test)))\n",
    "# #print(\"Test set R^2: {:.2f}\".format(regressorKNN.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "# #kfold \n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# accuracies=cross_val_score(estimator=regressorKNN, X=X_train, y=y_train, cv=10)\n",
    "# accuracies.mean()\n",
    "# accuracies.std()\n",
    "\n",
    "\n",
    "# #grid search\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "# parameters=[{'n_neighbors':[1,2,3,4,5,6] , 'weights':['uniform','distance'],'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']}]\n",
    "# gridsearch = GridSearchCV(estimator=regressorKNN   ,param_grid=parameters, cv=10, n_jobs=-1)\n",
    "# gridsearch=gridsearch.fit(X_train, y_train)\n",
    "# best_accuracy=gridsearch.best_score_\n",
    "# best_parameter=gridsearch.best_params_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the best Score is showing by RandomForest so we will use random forest for predicting the house price \n",
    "#model evaluation by  cross validation  and grid search to choose  best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
